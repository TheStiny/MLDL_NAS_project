# -*- coding: utf-8 -*-
"""download_resize_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14ctCKpvBAmjZGJE52HDlH1xb4O51DN44
"""

#!pip install pyvww

#!git clone https://github.com/Mxbonn/visualwakewords

#!bash visualwakewords/scripts/download_mscoco.sh path-to-COCO-dataset 2017

#TRAIN_ANNOTATIONS_FILE="path-to-mscoco-dataset/annotations/instances_train2017.json"
#VAL_ANNOTATIONS_FILE="path-to-mscoco-dataset/annotations/instances_val2017.json"
#DIR="path-to-mscoco-dataset/annotations/"
#!python visualwakewords/scripts/create_coco_train_minival_split.py \
#  --train_annotations_file="${TRAIN_ANNOTATIONS_FILE}" \
#  --val_annotations_file="${VAL_ANNOTATIONS_FILE}" \
#--output_dir="${DIR}"

#MAXITRAIN_ANNOTATIONS_FILE="path-to-mscoco-dataset/annotations/instances_maxitrain.json"
#MINIVAL_ANNOTATIONS_FILE="path-to-mscoco-dataset/annotations/instances_minival.json"
#VWW_OUTPUT_DIR="new-path-to-visualwakewords-dataset/annotations/"
#!python visualwakewords/scripts/create_visualwakewords_annotations.py \
#  --train_annotations_file="${MAXITRAIN_ANNOTATIONS_FILE}" \
#  --val_annotations_file="${MINIVAL_ANNOTATIONS_FILE}" \
#  --output_dir="${VWW_OUTPUT_DIR}" \
#  --threshold=0.005 \
#  --foreground_class='person'

import numpy as np
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import torchvision
from torchvision.models import mobilenet_v3_small
from torchvision import datasets
from torchvision import transforms as T
import torch.nn.functional as F
from torch.utils.data.sampler import SubsetRandomSampler
import tqdm
import pyvww
from torchvision.datasets import VisionDataset
from PIL import Image
import os
import os.path
from pyvww.utils import VisualWakeWords

#create dataset class
class VisualWakeWordsClassification(VisionDataset):
    """`Visual Wake Words <https://arxiv.org/abs/1906.05721>`_ Dataset.
    Args:
        root (string): Root directory where COCO images are downloaded to.
        annFile (string): Path to json visual wake words annotation file.
        transform (callable, optional): A function/transform that  takes in an PIL image
            and returns a transformed version. E.g, ``transforms.ToTensor``
        target_transform (callable, optional): A function/transform that takes in the
            target and transforms it.
    """
    def __init__(self, root, annFile, transform=T.ToTensor(), target_transform=None, transforms=None):
        super(VisualWakeWordsClassification, self).__init__(root, transforms, transform, target_transform)
        self.vww = VisualWakeWords(annFile)
        self.ids = list(sorted(self.vww.imgs.keys()))

    def __getitem__(self, index):
        """
        Args:
            index (int): Index
        Returns:
            tuple: Tuple (image, target). target is the index of the target class.
        """
        vww = self.vww
        img_id = self.ids[index]
        ann_ids = vww.getAnnIds(imgIds=img_id)
        if ann_ids:
            full_target = vww.loadAnns(ann_ids)
            categories = [ann['category_id'] for ann in full_target]
            if 1 in categories:
              target = 1  # l'immagine contiene una persona
            else:
              target = 0  # l'immagine non contiene una persona
        else:
            target = 0

        path = vww.loadImgs(img_id)[0]['file_name']

        img = Image.open(os.path.join(self.root, path)).convert('RGB')
        if self.transform is not None:
            img = self.transform(img)

        if self.target_transform is not None:
            target = self.target_transform(target)

        return img, target

import torch
import pyvww

train_dataset = VisualWakeWordsClassification(root="/content/path-to-COCO-dataset/train2017/",
                    annFile="/content/-to-mscoco-dataset/annotations/instances_train2017.json")

import torch
import pyvww

val_dataset = VisualWakeWordsClassification(root="/content/path-to-COCO-dataset/val2017/",
                    annFile="/content/-to-mscoco-dataset/annotations/instances_val2017.json")

from PIL import Image
import os, os.path

path = "/content/path-to-COCO-dataset/train2017/"
for f in os.listdir(path):
    img = Image.open(os.path.join(path,f))
    img_resized = img.resize((224, 224)) #resize train_dataset images to (224,224)
    img_resized.save(os.path.join(path,f), format='JPEG')

from PIL import Image
import os, os.path

path = "/content/path-to-COCO-dataset/val2017/"
for f in os.listdir(path):
    img = Image.open(os.path.join(path,f))
    img_resized = img.resize((224, 224)) #resize val_dataset images to (224,224)
    img_resized.save(os.path.join(path,f), format='JPEG')

#create tar file for train_dataset
#!tar -cvf /content/drive/MyDrive/train2017_160.tar /content/path-to-COCO-dataset/train2017/

#create tar file for val_dataset
#!tar -cvf /content/drive/MyDrive/val2017_160.tar /content/path-to-COCO-dataset/val2017/
